{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.utils import check_X_y\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, classification_report, make_scorer, f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import scale, MinMaxScaler, Normalizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:\\\\Users\\\\user\\\\Documents\\\\remote_sensing.csv\", sep=\";\")\n",
    "data.head()\n",
    "\n",
    "X,y = data.drop(\"class\", axis=1), data[\"class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling Configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f1_multi(y_true, y_pred): \n",
    "    return f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "f1_multi_scorer = make_scorer(f1_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Model - Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.562694461904\n",
      "0.285750043949\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(multi_class='ovr')\n",
    "lr.fit(X,y)\n",
    "\n",
    "lr_score = cross_val_score(lr,X,y,cv=cv)\n",
    "lr_score.mean()\n",
    "\n",
    "## f1\n",
    "\n",
    "lr_score_f1 = cross_val_score(lr,X,y,cv=cv,scoring=f1_multi_scorer)\n",
    "\n",
    "print(lr_score.mean())\n",
    "print(lr_score_f1.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.476961160164\n",
      "0.258925448937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "dc = DecisionTreeClassifier()\n",
    "dc_score = cross_val_score(dc,X,y,cv=cv)\n",
    "dc_score.mean()\n",
    "\n",
    "## f1\n",
    "\n",
    "dc_score_f1 = cross_val_score(dc,X,y,cv=cv,scoring=f1_multi_scorer)\n",
    "dc_score_f1.mean()\n",
    "\n",
    "print(dc_score.mean())\n",
    "print(dc_score_f1.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy classifier - Baseline (most_frequent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A machine learning algorithm tries to learn a function that models the relationship between the input data and the target variable. In order to measure performance a baseline model is used to compare any other machine learning algorithm against. In this specific classification case, the dummy classifier strategy used is “most_frequent”: always predicts the most frequent label in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.449240337624\n",
      "0.0774956295029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "dummy = DummyClassifier(strategy='most_frequent')\n",
    "dummy.fit(X,y)\n",
    "dummy_score = cross_val_score(dummy,X,y,cv=cv).mean()\n",
    "dummy_score \n",
    "\n",
    "#f1\n",
    "\n",
    "dummy_score_f1 = cross_val_score(dummy,X,y,cv=cv,scoring=f1_multi_scorer)\n",
    "dummy_score_f1.mean()\n",
    "\n",
    "\n",
    "print(dummy_score.mean())\n",
    "print(dummy_score_f1.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before performing any type of oversampling, both the logistic regression and the decision tree classifiers perform slightly better than the baseline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(random_state=0)\n",
    "forest.fit(X, y)\n",
    "forest_score = cross_val_score(forest,X,y,cv=cv).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forest_score_f1 = cross_val_score(forest,X,y,cv=cv,scoring=f1_multi_scorer).mean()\n",
    "\n",
    "print(forest_score.mean())\n",
    "print(forest_score_f1.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Similarly, the random forest classifier also performs slightly better than the baseline classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversampling Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is clearly an imbalanced problem, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Oversampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.935299373398\n",
      "0.649470137873\n",
      "0.796004377911\n",
      "0.929807796168\n",
      "0.646707577224\n",
      "0.794689407376\n"
     ]
    }
   ],
   "source": [
    "ros = RandomOverSampler()\n",
    "X_resampled, y_resampled = ros.fit_sample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.933662843775\n",
      "0.649470137873\n",
      "0.796004377911\n"
     ]
    }
   ],
   "source": [
    "dc_score_random = cross_val_score(dc,X_resampled,y_resampled,cv=cv)\n",
    "\n",
    "lr.fit(X_resampled,y_resampled)\n",
    "lr_score_random = cross_val_score(lr,X_resampled,y_resampled,cv=cv)\n",
    "\n",
    "forest.fit(X_resampled, y_resampled)\n",
    "forest_score_random = cross_val_score(forest,X_resampled,y_resampled,cv=cv).mean()\n",
    "\n",
    "print(dc_score_random.mean())\n",
    "print(lr_score_random.mean())\n",
    "print(forest_score_random.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.931072435564\n",
      "0.646707577224\n",
      "0.794689407376\n"
     ]
    }
   ],
   "source": [
    "dc_score_random_f1 = cross_val_score(dc,X_resampled,y_resampled,cv=cv,scoring=f1_multi_scorer)\n",
    "\n",
    "lr_score_random_f1 = cross_val_score(lr,X_resampled,y_resampled,cv=cv,scoring=f1_multi_scorer)\n",
    "\n",
    "forest_score_random_f1 = cross_val_score(forest,X_resampled,y_resampled,cv=cv,scoring=f1_multi_scorer).mean()\n",
    "\n",
    "\n",
    "print(dc_score_random_f1.mean())\n",
    "print(lr_score_random_f1.mean())\n",
    "print(forest_score_random_f1.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After performing random oversampling on the data set, the results improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.838251999627\n",
      "0.704360664156\n",
      "0.89752497588\n",
      "0.836034184929\n",
      "0.701353870956\n",
      "0.895492006521\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(ratio = 'auto',k_neighbors=1)\n",
    "X_res, y_res = sm.fit_sample(X, y)\n",
    "\n",
    "#accuracy\n",
    "\n",
    "dc_score_smote = cross_val_score(dc,X_res,y_res,cv=cv)\n",
    "\n",
    "lr.fit(X_res,y_res)\n",
    "lr_score_smote = cross_val_score(lr,X_res,y_res,cv=cv)\n",
    "\n",
    "forest.fit(X_res, y_res)\n",
    "forest_score_smote = cross_val_score(forest,X_res,y_res,cv=cv).mean()\n",
    "\n",
    "## f1\n",
    "\n",
    "dc_score_smote_f1 = cross_val_score(dc,X_res,y_res,cv=cv,scoring=f1_multi_scorer)\n",
    "\n",
    "lr.fit(X_res,y_res)\n",
    "lr_score_smote_f1 = cross_val_score(lr,X_res,y_res,cv=cv,scoring=f1_multi_scorer)\n",
    "\n",
    "forest.fit(X_res, y_res)\n",
    "forest_score_smote_f1 = cross_val_score(forest,X_res,y_res,cv=cv,scoring=f1_multi_scorer).mean()\n",
    "\n",
    "param_grid = {\n",
    "    \"max_depth\": [3,5,7,10,15],\n",
    "    \"max_features\": [1, 3, 10],\n",
    "    \"bootstrap\": [True, False],\n",
    "    \"criterion\": [\"gini\", \"entropy\"]\n",
    "}\n",
    "gscv = GridSearchCV(estimator=forest, param_grid=param_grid, cv=cv, scoring='accuracy')\n",
    "gscv.fit(X_res, y_res)\n",
    "gscv.best_score_\n",
    "\n",
    "print(dc_score_smote.mean())\n",
    "print(lr_score_smote.mean())\n",
    "print(forest_score_smote.mean())\n",
    "\n",
    "print(dc_score_smote_f1.mean())\n",
    "print(lr_score_smote_f1.mean())\n",
    "print(forest_score_smote_f1.mean())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To work with the SMOTE algorithm, it's important to first set the k_neighbors to 1 because of the class that has only 4 observations. Otherwise, the algorithm would not work. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.82      0.90      0.86       251\n",
      "          B       0.73      0.73      0.73       251\n",
      "          C       0.62      0.55      0.58       252\n",
      "          D       0.71      0.68      0.70       256\n",
      "          E       0.80      0.76      0.78       264\n",
      "          F       0.92      0.97      0.94       248\n",
      "          G       0.96      0.99      0.98       257\n",
      "          H       0.98      1.00      0.99       231\n",
      "\n",
      "avg / total       0.82      0.82      0.82      2010\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pca = PCA()\n",
    "normalizer = Normalizer()\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "steps = [('scaler', scaler),\n",
    "         ('pca', pca),\n",
    "         ('dt', dc),]\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.33, random_state=42)\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_prediction = pipeline.predict(X_test)\n",
    "report = classification_report(y_test, y_prediction)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.80      0.84      0.82       251\n",
      "          B       0.72      0.71      0.71       251\n",
      "          C       0.58      0.53      0.55       252\n",
      "          D       0.69      0.67      0.68       256\n",
      "          E       0.75      0.73      0.74       264\n",
      "          F       0.89      0.97      0.93       248\n",
      "          G       0.96      1.00      0.98       257\n",
      "          H       1.00      1.00      1.00       231\n",
      "\n",
      "avg / total       0.80      0.80      0.80      2010\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pca = PCA()\n",
    "steps = [('pca', pca),\n",
    "        ('dt', dc)]\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.33, random_state=42)\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_prediction = pipeline.predict(X_test)\n",
    "report1 = classification_report(y_test, y_prediction)\n",
    "print(report1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One vs Rest Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This strategy consists in fitting one classifier per class. For each classifier, the class is fitted against all the other classes. In addition to its computational efficiency (only n_classes classifiers are needed).\n",
    "\n",
    "**Advantage: Interpretability.** *Since each class is represented by one and one classifier only, it is possible to gain knowledge about the class by inspecting its corresponding classifier. This is the most commonly used strategy for multiclass classification and is a fair default choice.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.94      0.78      0.86       251\n",
      "          B       0.88      0.58      0.70       251\n",
      "          C       0.71      0.49      0.58       252\n",
      "          D       0.72      0.66      0.69       256\n",
      "          E       0.78      0.73      0.75       264\n",
      "          F       0.94      0.94      0.94       248\n",
      "          G       0.97      0.99      0.98       257\n",
      "          H       0.49      1.00      0.66       231\n",
      "\n",
      "avg / total       0.81      0.77      0.77      2010\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_ovr = OneVsRestClassifier(dc).fit(X_train, y_train).predict(X_test)\n",
    "report2 = classification_report(y_test, y_ovr)\n",
    "print(report2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC curves are typically used in binary classification to study the output of a classifier. In order to extend ROC curve and ROC area to multi-class or multi-label classification, it is necessary to binarize the output. One ROC curve can be drawn per label, but one can also draw a ROC curve by considering each element of the label indicator matrix as a binary prediction (micro-averaging).\n",
    "\n",
    "Another evaluation measure for multi-class classification is macro-averaging, which gives equal weight to the classification of each label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binarize labels in a one-vs-all fashion\n",
    "\n",
    "Several regression and binary classification algorithms are available in the scikit. \n",
    "A simple way to extend these algorithms to the multi-class classification case is to use the so-called one-vs-all scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91475032851511173"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
